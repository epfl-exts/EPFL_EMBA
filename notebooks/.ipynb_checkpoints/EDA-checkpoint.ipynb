{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/aiml2days.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"aiml2days/notebooks/data\" \"aiml2days/notebooks/data_prep_tools.py\" \"aiml2days/notebooks/EDA_tools.py\" \"aiml2days/notebooks/modeling_tools.py\" . \n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"aiml2days/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "%run data_prep_tools.py\n",
    "%run EDA_tools.py\n",
    "%run modeling_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Loading features  \n",
    "\n",
    "All three feature spaces can be loaded using the `load_feature_space()`function.  \n",
    "\n",
    "The parameter `features` specifies which of the above features you want to load. The options are:\n",
    "\n",
    "The different feature sets can be loaded with the `load_feature_space()`-function by changing the string after `features=`. The options are:\n",
    "* \"num\": numerical features\n",
    "* \"text\": (default) text features\n",
    "* \"num_text\": numerical and text features combined\n",
    "* \"embedding\": embedding features\n",
    "  \n",
    "The parameter `no_labels` controls whether we want to omit the labels. The options for are:\n",
    "- `True` to omit the labels\n",
    "- `False` (default) to load the labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task \n",
    "\n",
    "Explore the different feature spaces.\n",
    "\n",
    "Disclaimer: For easy of analysis we will analyze the full data set. In practice when building a supervised learning model like a spam filter you create a training set and a test set. You can explore the training set and used the insights to build your model. But you don't explore the test set as it is used to evaluate the performance of the model on unseen data. \n",
    "\n",
    "### Notebook overview\n",
    "\n",
    "* Explore the numeric features\n",
    "* Explore the text features\n",
    "* Explore the embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by exploring the distribution of the labels i.e. how many spam and non-spam emails we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_frequency(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ What do you observe for the frequency of spam and non-spam emails? \n",
    "\n",
    "__Q2.__ How could that impact the training of the spam detector?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the features\n",
    "\n",
    "### Numeric features\n",
    " The numeric features are:\n",
    "- \"email_counts\"\n",
    "- \"html tag_counts\"\n",
    "- \"url_counts\"\n",
    "- \"Twitter username_counts\"\n",
    "- \"hashtag_counts\"\n",
    "- \"character_counts\"\n",
    "- \"word_counts\"\n",
    "- \"unique word_counts\"\n",
    "- \"punctuation mark_counts\"\n",
    "- \"uppercase word_counts\"\n",
    "- \"lowercase word_counts\"\n",
    "- \"digit_counts\"\n",
    "- \"alphabetic char_counts\"\n",
    "\n",
    "Note some features have been log-scaled.\n",
    "\n",
    "#### Load the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_df = load_feature_space(features=\"num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distributions of the numeric features \n",
    "- once across the full corpus and\n",
    "- once by `spam_label`   \n",
    "\n",
    "and see whether there are signs of differences between spam and non-spam emails.\n",
    "\n",
    "#### Full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_features(num_features_df, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By `spam_label`:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ Do spam and non-spam emails differ on average acorss different numeric features?\n",
    "\n",
    "* Do spams contain more HTML tags? \n",
    "* Does non-spam contain more URLs and E-mail adresses? \n",
    "* Are spams mails longer than non-spam? \n",
    "* ...\n",
    "   \n",
    "__Q2.__ Could these features be useful for the distinction of spam and non-spam emails?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_features(num_features_df, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text features\n",
    "\n",
    "It is easier to work with the cleaned text before we applied the vectorizers to generate a specific feature space.\n",
    "\n",
    "#### Load the cleaned text::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = load_source_data(verbose=False)\n",
    "df_cleaned = clean_corpus(df_source, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "__Q1.__ Before we start the analysis, which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Global view:**   \n",
    "Let's explore the cleaned text for the most common words overall. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_words(df_cleaned, N=30, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class-focused view:**  \n",
    "We are taking the top `N` words from each class and combining them into one set. The words are sorted by their frequency in the non-spam class (blue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "__Q1.__ Which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "__Q2.__ Are the total counts representative of the importance to each class? Hint: What about the class sizes?\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_tokens(df_cleaned, N=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the above counts but this time we account for the different class sizes. We will use the relative frequencies adjusted by adjusting our counts to 1000 documents per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "__Q1.__ Which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "__Q2.__ What has changed in terms of words that appear to be good indicators for either class?\n",
    "\n",
    "__Q3.__ Playing around a bit with `N`, do you think building a model based on text features can yield some good results?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_tokens(df_cleaned, N=15, per_1000=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the embedding space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = load_feature_space(features=\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction for plotting \n",
    "\n",
    "We run a PCA (so called Principal Component Analysis) on the embedding space. This tells use whether we can reduce the overall dimension needed for the embedding space. Less features means less complexity and less noise, and thus less chance for our models to overfit.\n",
    "\n",
    "We will also visualize the first two components in a scatter plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "__Q1.__ By how much could the feature space shrink if we wanted to retain 90% of variance? (Orignal size 768 features)\n",
    "\n",
    "__Q2.__ Looking at the scatterplot, what insights can you draw from the PCA results regarding class separation? \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pca_df = run_pca(embeddings_df, with_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml2024]",
   "language": "python",
   "name": "conda-env-adsml2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
