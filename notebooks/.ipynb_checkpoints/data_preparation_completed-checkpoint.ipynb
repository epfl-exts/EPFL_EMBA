{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/aiml2days.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"aiml2days/notebooks/data\" \"aiml2days/notebooks/data_prep_tools.py\" \"aiml2days/notebooks/EDA_tools.py\" \"aiml2days/notebooks/modeling_tools.py\" . \n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"aiml2days/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Notebook overview\n",
    "\n",
    "Our overall goal of the hands-on session is to explore and compare various features space and machine learning approaches. In this notebook we will focus getting the data ready for this tasks. \n",
    "\n",
    "We will:\n",
    "\n",
    "* Load the raw data\n",
    "* Explore different samples of raw email and decide on text preprocessing steps\n",
    "* Preprocessing the raw text of the email\n",
    "* Extracting different features from the data\n",
    "* Store the different sets of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "We use the [SpamAssassin](https://spamassassin.apache.org/), a public email corpus. The dataset is available in the *data* folder. You can more details about this dataset [here](https://spamassassin.apache.org/old/publiccorpus/).\n",
    "\n",
    "\n",
    "The dataset contains **~6'000 labeled emails**, i.e. we know which emails are regular emails and which are flagged as spam.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our goal is to explore and compare various features spaces and machine learning approaches. The use of spam emails is just for demonstration and learning purpose as it is a text-based example that everyone is easily familiar with and that allows us to highlight different stages of developing a machine learning application and the decision making processes involved along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "%run data_prep_tools.py\n",
    "%run EDA_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8546 emails loaded\n",
      "Cleaning data set:\n",
      "2710 duplicate emails found and removed\n",
      "4 empty emails found and removed\n",
      "\n",
      "5832 emails remaining\n",
      "\n",
      "Number of columns: 2\n",
      "Columns names:\n",
      "spam_label, text\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df_source = load_source_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1</td>\n",
       "      <td>PUBLIC ANNOUNCEMENT: The new domain names are finally available to the general public at discount prices. Now you can register one of the exciting new .BIZ or .INFO domain names, as well as the original .COM and .NET names for just $14.95. These brand new domain extensions were recently approved by ICANN and have the same rights as the original .COM and .NET domain names. The biggest benefit is of-course that the .BIZ and .INFO domain names are currently more available. i.e. it will be much easier to register an attractive and easy-to-remember domain name for the same price. Visit: http://www.affordable-domains.com today for more info. Register your domain name today for just $14.95 at: http://www.affordable-domains.com/ Registration fees include full access to an easy-to-use control panel to manage your domain name in the future. Sincerely, Domain Administrator Affordable Domains To remove your email address from further promotional mailings from this company, click here: http://www.centralremovalservice.com/cgi-bin/domain-remove.cgi 45 9588xeOa0-732ENqv9875eRMa4-664oWoA0829MnbA5-849OhZo1243goAl55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi all I have a prob when trying to install Linux (tried RedHat, Suse) on my laptop. I can start the install but after about 2min, the whole pc just dies. I know it's not a Linux prob and here is what I have encountered: I had the same problem when installing Win on it and eventually sorted it out by disabling the infrared port. I'm guessing this might be same prob although I'm not sure. I am very new to Linux so it's not that easy for me to work it out. I did manage to follow the setup procedure at one stage (using images on disks) and it cuts out either as it's trying to verify what CD-Rom I have or just after (hence my suspicion of the infrared port again). can anyone help ? thanks Gianni ************************************************************************ This e-mail and any files transmitted with it are confidential and intended solely for the use of the individual or entity to which they are addressed. If you have received this e-mail in error, please notify the EPA postmaster - postmaster@epa.ie The opinions contained within are personal to the sender and do not necessarily reflect the policy of the Environmental Protection Agency. This footnote also confirms that this e-mail message has been swept by MIMEsweeper for the presence of computer viruses. ************************************************************************ -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>0</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-1,8622126,215/ Date: 2002-10-07T03:52:50+01:00 *Money:* Pensions experts say tax lures should be used to raise retirement age.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam_label  \\\n",
       "1696           1   \n",
       "2007           0   \n",
       "3573           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \n",
       "1696                                                                                                                                                                                                                                                                                                                                                                                                             PUBLIC ANNOUNCEMENT: The new domain names are finally available to the general public at discount prices. Now you can register one of the exciting new .BIZ or .INFO domain names, as well as the original .COM and .NET names for just $14.95. These brand new domain extensions were recently approved by ICANN and have the same rights as the original .COM and .NET domain names. The biggest benefit is of-course that the .BIZ and .INFO domain names are currently more available. i.e. it will be much easier to register an attractive and easy-to-remember domain name for the same price. Visit: http://www.affordable-domains.com today for more info. Register your domain name today for just $14.95 at: http://www.affordable-domains.com/ Registration fees include full access to an easy-to-use control panel to manage your domain name in the future. Sincerely, Domain Administrator Affordable Domains To remove your email address from further promotional mailings from this company, click here: http://www.centralremovalservice.com/cgi-bin/domain-remove.cgi 45 9588xeOa0-732ENqv9875eRMa4-664oWoA0829MnbA5-849OhZo1243goAl55  \n",
       "2007  Hi all I have a prob when trying to install Linux (tried RedHat, Suse) on my laptop. I can start the install but after about 2min, the whole pc just dies. I know it's not a Linux prob and here is what I have encountered: I had the same problem when installing Win on it and eventually sorted it out by disabling the infrared port. I'm guessing this might be same prob although I'm not sure. I am very new to Linux so it's not that easy for me to work it out. I did manage to follow the setup procedure at one stage (using images on disks) and it cuts out either as it's trying to verify what CD-Rom I have or just after (hence my suspicion of the infrared port again). can anyone help ? thanks Gianni ************************************************************************ This e-mail and any files transmitted with it are confidential and intended solely for the use of the individual or entity to which they are addressed. If you have received this e-mail in error, please notify the EPA postmaster - postmaster@epa.ie The opinions contained within are personal to the sender and do not necessarily reflect the policy of the Environmental Protection Agency. This footnote also confirms that this e-mail message has been swept by MIMEsweeper for the presence of computer viruses. ************************************************************************ -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie  \n",
       "3573                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    URL: http://www.newsisfree.com/click/-1,8622126,215/ Date: 2002-10-07T03:52:50+01:00 *Money:* Pensions experts say tax lures should be used to raise retirement age.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you rerun this cell multiple times you get different samples displayed each time\n",
    "# OR you can replace the number 3 with a number of your choice\n",
    "display(df_source.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Text preprocessing\n",
    "\n",
    "The goal of text preprocessing is to clean up and transform the raw text into a format that can be used by machine learning algorithms.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**In the Warmup Task we asked:**\n",
    "    \n",
    "__Q1.__ What parts of the text do we think are noise?\n",
    "   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Observations\n",
    "\n",
    "1. Some suggestions discussed in class:\n",
    "\n",
    "* HTML tags \n",
    "* URLs\n",
    "* E-mail addresses\n",
    "* Punctuation marks, digits (e.g. 2002, 1.1, ...)\n",
    "* Multiple whitespaces\n",
    "* Case conversion (e.g. Dog vs dog, ...)\n",
    "* English STOPWORDS (e.g. a, is, my, i, all, and, by...)\n",
    "* ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *clean_corpus* function below will take care of the above points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5832\n",
      "Number of columns: 3\n",
      "Columns names:\n",
      "spam_label, text, text_cleaned\n",
      "\n",
      "Number of duplicate cleaned texts found: 279\n",
      "Number of empty texts found: 27\n",
      "\n",
      "Email texts cleaned\n",
      "Number of samples: 5832\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = clean_corpus(df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original document:\n",
      "\n",
      "Anarchist 'Scavenger Hunt' Raises D.C. Police Ire Sat Sep 21, 3:37 PM ET WASHINGTON (Reuters) - An\n",
      "online \"anarchist scavenger hunt\" proposed for next week's annual meeting of the International\n",
      "Monetary Fund ( news - web sites) and World Bank ( news - web sites) here has raised the ire of\n",
      "police, who fear demonstrators could damage property and wreak havoc. Break a McDonald's window, get\n",
      "300 points. Puncture a Washington D.C. police car tire to win 75 points. Score 400 points for a pie\n",
      "in the face of a corporate executive or World Bank delegate. D.C. Assistant Police Chief Terrance\n",
      "Gainer told a congressional hearing on Friday that law authorities were in talks to decide whether\n",
      "planned protests were, \"so deleterious to security efforts that we ought to take proactive action.\"\n",
      "Several thousand people are expected to demonstrate outside the IMF and World Bank headquarters next\n",
      "weekend. The Anti-Capitalist Convergence, a D.C.-based anarchist group, is also planning a day-long\n",
      "traffic blockade, banner-drops and protests against major corporations in the downtown core. Chuck,\n",
      "the 37 year-old webmaster of the anarchist site www.infoshop.org who declined to give his last name,\n",
      "told Reuters his scavenger hunt was meant as a joke. \"People were asking for things to do when they\n",
      "come to D.C. We made the list to get people thinking, so they don't do the boring, standard stuff,\"\n",
      "he said. \"I doubt people will actually keep track of what they do for points.\"\n",
      "\n",
      "Cleaned document:\n",
      "\n",
      "anarchist scavenger hunt raises police washington reuters online anarchist scavenger hunt proposed\n",
      "weeks annual meeting international monetary fund news sites world bank news sites raised police fear\n",
      "demonstrators damage property wreak havoc break mcdonalds window points puncture washington police\n",
      "tire points score points face corporate executive world bank delegate assistant police chief\n",
      "terrance gainer told congressional hearing friday authorities talks decide planned protests\n",
      "deleterious security efforts ought proactive action thousand people expected demonstrate outside\n",
      "world bank headquarters weekend anti capitalist convergence based anarchist group planning long\n",
      "traffic blockade banner drops protests major corporations downtown core chuck year webmaster\n",
      "anarchist site infoshop declined told reuters scavenger hunt meant joke people asking things come\n",
      "list people thinking dont boring standard stuff said doubt people actually track points\n"
     ]
    }
   ],
   "source": [
    "# Let's look at some examples.\n",
    "# You can rerun this cell to get a different sample\n",
    "show_clean_text(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering \n",
    "\n",
    "## Part 1: Extracting numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**In the Warmup Task we asked:**\n",
    "       \n",
    "__Q2.__ What should we do with these parts of the text?\n",
    "</div>\n",
    "\n",
    "The function *extract_numeric* counts the frequencies of the items in our list above and stores them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples and columns of input: (5832, 2)\n",
      "Number of columns: 2\n",
      "Columns names:\n",
      "spam_label, text\n",
      "\n",
      "Numeric features extracted\n",
      "Data size: (5832, 14)\n",
      "Number of columns: 14\n",
      "Columns names:\n",
      "email_counts, html tag_counts, url_counts, Twitter username_counts, hashtag_counts\n",
      "character_counts, word_counts, unique word_counts, punctuation mark_counts, uppercase word_counts\n",
      "lowercase word_counts, digit_counts, alphabetic char_counts, spam_label\n",
      "Numeric features saved to data/num_features.csv\n"
     ]
    }
   ],
   "source": [
    "num_features_df = extract_numeric_features(df=df_source, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "## Part 2: Extracting features from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to give the texts a structure that the computercan handle we represent the text as vectors, those are _long lists of numbers_.\n",
    "\n",
    "We call these methods vectorizers. The _extract_text_features_ function offers two options  \n",
    "1. `vectorizer=\"count\"`  \n",
    "This gives the bag of words model which simply counts how often different word appear in each email.\n",
    "2. `vectorizer=\"tfidf\"`  \n",
    "TF-IDF stands for **Term Frequency–Inverse Document Frequency**. This approach takes into account how frequent a word is in the email, and how common it is in the entire dataset. It gives us a weighted count of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer selected\n",
      "Text features saved to 'data/text_features_count.csv'\n",
      "Shape of our feature space: (5832, 10001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aalib</th>\n",
       "      <th>aall</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abacha</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abiword</th>\n",
       "      <th>...</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zine</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonealarm</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zope</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zyban</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aalib  aall  aaron  abacha  abandon  abandoned  abidjan  abilities  \\\n",
       "0      0     0      0       0        0          0        0          0   \n",
       "1      0     0      0       0        0          0        0          0   \n",
       "2      0     0      0       0        0          0        0          0   \n",
       "\n",
       "   ability  abiword  ...  zimbabwe  zine  zone  zonealarm  zones  zoom  zope  \\\n",
       "0        0        0  ...         0     0     0          0      0     0     0   \n",
       "1        0        0  ...         0     0     0          0      0     0     0   \n",
       "2        0        0  ...         0     0     0          0      0     0     0   \n",
       "\n",
       "   zurich  zyban  spam_label  \n",
       "0       0      0           1  \n",
       "1       0      0           1  \n",
       "2       0      0           1  \n",
       "\n",
       "[3 rows x 10001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_features_df = extract_text_features(\n",
    "    df_cleaned, vectorizer=\"count\", with_labels=True, store=True\n",
    ")\n",
    "print(\"Shape of our feature space:\", text_features_df.shape)\n",
    "\n",
    "display(text_features_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer selected\n",
      "Text features saved to 'data/text_features_tfidf.csv'\n",
      "Shape of our feature space: (5832, 10001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aalib</th>\n",
       "      <th>aall</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abacha</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abiword</th>\n",
       "      <th>...</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zine</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonealarm</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zope</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zyban</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aalib  aall  aaron  abacha  abandon  abandoned  abidjan  abilities  \\\n",
       "0    0.0   0.0    0.0     0.0      0.0        0.0      0.0        0.0   \n",
       "1    0.0   0.0    0.0     0.0      0.0        0.0      0.0        0.0   \n",
       "2    0.0   0.0    0.0     0.0      0.0        0.0      0.0        0.0   \n",
       "\n",
       "   ability  abiword  ...  zimbabwe  zine  zone  zonealarm  zones  zoom  zope  \\\n",
       "0      0.0      0.0  ...       0.0   0.0   0.0        0.0    0.0   0.0   0.0   \n",
       "1      0.0      0.0  ...       0.0   0.0   0.0        0.0    0.0   0.0   0.0   \n",
       "2      0.0      0.0  ...       0.0   0.0   0.0        0.0    0.0   0.0   0.0   \n",
       "\n",
       "   zurich  zyban  spam_label  \n",
       "0     0.0    0.0           1  \n",
       "1     0.0    0.0           1  \n",
       "2     0.0    0.0           1  \n",
       "\n",
       "[3 rows x 10001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_features_df2 = extract_text_features(\n",
    "    df_cleaned, vectorizer=\"tfidf\", with_labels=True, store=True\n",
    ")\n",
    "print(\"Shape of our feature space:\", text_features_df2.shape)\n",
    "\n",
    "display(text_features_df2.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Bag of Words and TF-IDF approaches cannot capture the meaning of words or the relationships between them. They also lead to very high-dimensional and sparse representations of the text which are not very efficient and can lead to overfitting.\n",
    "\n",
    "### Embeddings\n",
    "Embeddings are denser vector representations representing similar words as similar vectors to capture meaning and relationships.\n",
    "\n",
    "We have already extracted the features for you by passing them through language model. the features are available in the file named `email_embeddings.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email embeddings loaded\n",
      "Data includes labels in the column 'spam_label'\n",
      "The data set has 5832 rows, 769 columns\n",
      "Shape of our feature space: (5832, 769)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012373</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>-0.015448</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.035560</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>-0.013540</td>\n",
       "      <td>-0.019357</td>\n",
       "      <td>0.043482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044551</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>0.029587</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.017245</td>\n",
       "      <td>-0.009922</td>\n",
       "      <td>-0.034954</td>\n",
       "      <td>-0.039636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.036461</td>\n",
       "      <td>-0.025587</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>-0.045625</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>-0.002957</td>\n",
       "      <td>0.040964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.048945</td>\n",
       "      <td>-0.039095</td>\n",
       "      <td>0.036534</td>\n",
       "      <td>-0.025406</td>\n",
       "      <td>-0.004709</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.029345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015628</td>\n",
       "      <td>-0.032974</td>\n",
       "      <td>-0.017868</td>\n",
       "      <td>0.030587</td>\n",
       "      <td>0.015972</td>\n",
       "      <td>-0.012683</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.008228</td>\n",
       "      <td>-0.026466</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034141</td>\n",
       "      <td>-0.034710</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>-0.043653</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>-0.027863</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.029882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.012373 -0.018983 -0.015448  0.017502  0.035560 -0.000460  0.033559   \n",
       "1 -0.000592 -0.036461 -0.025587  0.017729  0.031857 -0.045625  0.051302   \n",
       "2 -0.015628 -0.032974 -0.017868  0.030587  0.015972 -0.012683  0.016617   \n",
       "\n",
       "          7         8         9  ...       759       760       761       762  \\\n",
       "0 -0.013540 -0.019357  0.043482  ...  0.044551  0.022994  0.029587  0.011559   \n",
       "1  0.025131 -0.002957  0.040964  ...  0.036356  0.004606  0.048945 -0.039095   \n",
       "2 -0.008228 -0.026466  0.017005  ...  0.034141 -0.034710  0.015784 -0.043653   \n",
       "\n",
       "        763       764       765       766       767  spam_label  \n",
       "0 -0.008164 -0.017245 -0.009922 -0.034954 -0.039636           1  \n",
       "1  0.036534 -0.025406 -0.004709 -0.006947 -0.029345           1  \n",
       "2  0.021216  0.010660 -0.027863 -0.005670 -0.029882           1  \n",
       "\n",
       "[3 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_df = load_feature_space(features=\"embedding\")\n",
    "\n",
    "print(\"Shape of our feature space:\", embeddings_df.shape)\n",
    "\n",
    "display(embeddings_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml2024]",
   "language": "python",
   "name": "conda-env-adsml2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
