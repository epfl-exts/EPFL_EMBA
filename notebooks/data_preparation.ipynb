{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/EPFL_EMBA.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"EPFL_EMBA/notebooks/data\" \"EPFL_EMBA/notebooks/data_prep_tools.py\" \"EPFL_EMBA/notebooks/EDA_tools.py\" \"EPFL_EMBA/notebooks/modeling_tools.py\" . \n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"EPFL_EMBA/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Notebook overview\n",
    "\n",
    "Our overall goal of the hands-on session is to explore and compare various features space and machine learning approaches. In this notebook we will focus getting the data ready for this tasks. \n",
    "\n",
    "We will:\n",
    "\n",
    "* Load the raw data\n",
    "* Explore different samples of raw email and decide on text preprocessing steps\n",
    "* Preprocessing the raw text of the email\n",
    "* Extracting different features from the data\n",
    "* Store the different sets of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "We use the [SpamAssassin](https://spamassassin.apache.org/), a public email corpus. The dataset is available in the *data* folder. You can more details about this dataset [here](https://spamassassin.apache.org/old/publiccorpus/).\n",
    "\n",
    "\n",
    "The dataset contains **~6'000 labeled emails**, i.e. we know which emails are regular emails and which are flagged as spam.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our goal is to explore and compare various features spaces and machine learning approaches. The use of spam emails is just for demonstration and learning purpose as it is a text-based example that everyone is easily familiar with and that allows us to highlight different stages of developing a machine learning application and the decision making processes involved along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "%run data_prep_tools.py\n",
    "%run EDA_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_source = load_source_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you rerun this cell multiple times you get different samples displayed each time\n",
    "# OR you can replace the number 3 with a number of your choice\n",
    "display(df_source.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Text preprocessing\n",
    "\n",
    "The goal of text preprocessing is to clean up and transform the raw text into a format that can be used by machine learning algorithms.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**In the Warmup Task we asked:**\n",
    "    \n",
    "__Q1.__ What parts of the text do we think are noise?\n",
    "   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "1. Some suggestions discussed in class:\n",
    "\n",
    "* HTML tags \n",
    "* URLs\n",
    "* E-mail addresses\n",
    "* Punctuation marks, digits (e.g. 2002, 1.1, ...)\n",
    "* Multiple whitespaces\n",
    "* Case conversion (e.g. Dog vs dog, ...)\n",
    "* English STOPWORDS (e.g. a, is, my, i, all, and, by...)\n",
    "* ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *clean_corpus* function below will take care of the above points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_corpus(df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some examples.\n",
    "# You can rerun this cell to get a different sample\n",
    "show_clean_text(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering \n",
    "\n",
    "## Part 1: Extracting numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**In the Warmup Task we asked:**\n",
    "       \n",
    "__Q2.__ What should we do with these parts of the text?\n",
    "</div>\n",
    "\n",
    "The function *extract_numeric* counts the frequencies of the items in our list above and stores them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_df = extract_numeric_features(df=df_source, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "## Part 2: Extracting features from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to give the texts a structure that the computercan handle we represent the text as vectors, those are _long lists of numbers_.\n",
    "\n",
    "We call these methods vectorizers. The _extract_text_features_ function offers two options  \n",
    "1. `vectorizer=\"count\"`  \n",
    "This gives the bag of words model which simply counts how often different word appear in each email.\n",
    "2. `vectorizer=\"tfidf\"`  \n",
    "TF-IDF stands for **Term Frequencyâ€“Inverse Document Frequency**. This approach takes into account how frequent a word is in the email, and how common it is in the entire dataset. It gives us a weighted count of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_df = extract_text_features(\n",
    "    df_cleaned, vectorizer=\"count\", with_labels=True, store=True\n",
    ")\n",
    "print(\"Shape of our feature space:\", text_features_df.shape)\n",
    "\n",
    "display(text_features_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_df2 = extract_text_features(\n",
    "    df_cleaned, vectorizer=\"tfidf\", with_labels=True, store=True\n",
    ")\n",
    "print(\"Shape of our feature space:\", text_features_df2.shape)\n",
    "\n",
    "display(text_features_df2.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Bag of Words and TF-IDF approaches cannot capture the meaning of words or the relationships between them. They also lead to very high-dimensional and sparse representations of the text which are not very efficient and can lead to overfitting.\n",
    "\n",
    "### Embeddings\n",
    "Embeddings are denser vector representations representing similar words as similar vectors to capture meaning and relationships.\n",
    "\n",
    "We have already extracted the features for you by passing them through language model. the features are available in the file named `email_embeddings.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = load_feature_space(features=\"embedding\")\n",
    "\n",
    "print(\"Shape of our feature space:\", embeddings_df.shape)\n",
    "\n",
    "display(embeddings_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml2024]",
   "language": "python",
   "name": "conda-env-adsml2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
